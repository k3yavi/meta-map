{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import pysam\n",
    "import pandas as pd\n",
    "import os\n",
    "import math\n",
    "import click\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mil = 1000000\n",
    "hund = 100\n",
    "\n",
    "def populate_phylum_dict(pname):\n",
    "    with open(pname) as f:\n",
    "        data = pd.read_table(f).set_index('EMBL ID').drop([\"Strain/species details\"], axis=1).to_dict()[\"Phylum\"]\n",
    "    id2phlm = {}\n",
    "    for k,v in data.items():\n",
    "        nk = k.split(\".\")[0]\n",
    "        id2phlm[nk] = v\n",
    "        if (nk == \"CM000636\"):\n",
    "            id2phlm[\"CP006835\"] = v\n",
    "        elif v == \"Rhizobium_Bradyrhizobium\":\n",
    "            id2phlm[nk] = \"Proteobacteria\"\n",
    "        elif v == \"Pathogens\":\n",
    "            id2phlm[nk] = \"Proteobacteria\"\n",
    "    id2phlm[\"Rose\"] = \"Rose\"\n",
    "    id2phlm[\"Eukaryotes\"] = \"Eukaryotes\"\n",
    "    del data\n",
    "    return id2phlm\n",
    "\n",
    "def get_ref_id(aln):\n",
    "    # get id for the mapped reference\n",
    "    rname = aln.reference_name\n",
    "\n",
    "    euList = [\"Arabidopsis\", \"Human\", \"Lizard\", \"Chicken\", \"Eagle\", \"Turtle\", \"Yeast\"]\n",
    "    for eu in euList:\n",
    "        if eu in rname:\n",
    "            return \"Eukaryotes\"\n",
    "\n",
    "    if \"Rose\" in rname:\n",
    "        return \"Rose\"\n",
    "    try:\n",
    "        return aln.reference_name.split(\"|\")[1]\n",
    "    except:\n",
    "        return aln.reference_name.split(\".\")[0]\n",
    "\n",
    "def get_query_id(aln):\n",
    "    qname = aln.query_name\n",
    "\n",
    "    # get ground truth id\n",
    "    if \"Eukaryotes\" in qname:\n",
    "        return \"Eukaryotes\"\n",
    "    elif \"Rose\" in qname:\n",
    "        return \"Rose\"\n",
    "\n",
    "    qId = qname.split('-')[0]\n",
    "    if \"|\" in qId:\n",
    "        qId = qId.split(\"|\")[1]\n",
    "    elif \"_\" in qId:\n",
    "        qId = qId.split(\"_\")[0]\n",
    "\n",
    "    return qId\n",
    "\n",
    "def print_details(qId, rIds, aln):\n",
    "    print (\"ALIGNMENT\", file=sys.stderr)\n",
    "    print (aln, file=sys.stderr )\n",
    "    print (\"PHYLA\", file=sys.stderr)\n",
    "    print (\"QUERY:\\t\" + qId + \"\\tMAPPINGS:\", end=\"\\t\", file=sys.stderr)\n",
    "    for rId in rIds:\n",
    "        print ( rId , end=\"\\t\", file=sys.stderr)\n",
    "    print (\"\\n\", file=sys.stderr)\n",
    "\n",
    "def parse_fq(rname):\n",
    "    totReads = 0\n",
    "    TN = 0\n",
    "    reads_list = []\n",
    "    with open(rname) as f:\n",
    "        for line in f:\n",
    "            # counting total reads\n",
    "            totReads += 1\n",
    "            # Progress Monitoring\n",
    "            if(totReads % mil == 0):\n",
    "                print (\"\\r Done reading {} Million reads from FASTQ.\".format(int(round(totReads)/1000000)), end=\"\")\n",
    "                sys.stdout.flush()\n",
    "\n",
    "            #extracting relevant part of read\n",
    "            read = line.strip().replace(\"/1\",\"\").replace(\"@\",\"\")\n",
    "\n",
    "            if \"Random\" in read:\n",
    "                TN += 1\n",
    "\n",
    "            #making a list of read id\n",
    "            reads_list.append(read)\n",
    "\n",
    "            # skip next 4 lines\n",
    "            for _ in range(3):\n",
    "                f.next()\n",
    "\n",
    "    if len(reads_list) != len(set(reads_list)):\n",
    "        print (\"ERROR: Repeating reads found\")\n",
    "        exit(1)\n",
    "    return totReads, TN, reads_list\n",
    "\n",
    "def print_stats(singCount, totCount, totReads, TP, FP, TN, orphanCount):\n",
    "    mmCount = round(totCount - singCount)\n",
    "    unmapCount = totReads - totCount\n",
    "    FN = totReads - TP - FP - TN\n",
    "    cwd = os.getcwd()\n",
    "\n",
    "    sen = TP/float(TP+FN)\n",
    "    spec = TN/float(TN+FP)\n",
    "    ppv = TP/float(TP+FP)\n",
    "    npv = TN/float(TN+FN)\n",
    "    mcc = ((TP*TN)-(FP*FN)) / math.sqrt( (TP+FP)*(TP+FN)*(TN+FP)*(TN+FN)  )\n",
    "    stText = \"\\n\\n\" + \\\n",
    "    \"====================================================================================\\n\" + \\\n",
    "    \"Total Number of reads: {0} ({1:.2f}M)\\n\".format(totReads, totReads/mil)+ \\\n",
    "    \"Number of Unmapped reads: {0} ({1:.2f}M, {2:.2f}%)\\n\".format(unmapCount, unmapCount/mil, unmapCount*hund/totReads)+ \\\n",
    "    \"Number of Mapped reads {0}({1:.2f}M, {2:.2f}%)\\n\".format(totCount, totCount/mil, totCount*hund/totReads)+ \\\n",
    "    \"\\n\\n\"+ \\\n",
    "    \"============================ OUT OF MAPPED READS ===================================\\n\"+ \\\n",
    "    \"Number of Singly Mapped reads: {0} ({1:.2f}M, {2:.2f}%)\\n\".format(singCount, singCount/mil, singCount*hund/totReads)+ \\\n",
    "    \"Number of Multimapped reads: {0} ({1:.2f}M, {2:.2f}%)\\n\".format(mmCount, mmCount/mil, mmCount*hund/totReads)+ \\\n",
    "    \"Number of Orphaned (Ignored)ALIGNMENTS (Should be significantly low): {}\\n\".format(orphanCount)+ \\\n",
    "    \"====================================================================================\\n\"+ \\\n",
    "    \"\\n ===================== \\n ACCURACY METRIC \\n =====================\\n\"+ \\\n",
    "    \"Number of True positives(TP) reads: {0} ({1:.2f}M, {2:.2f}%)\\n\".format(TP, TP/mil, TP*hund/totReads)+ \\\n",
    "    \"Number of False Negatives(FN) reads: {0} ({1:.2f}M, {2:.2f}%)\\n\".format(FN, FN/mil, FN*hund/totReads)+ \\\n",
    "    \"Number of False positives(FP) reads: {0} ({1:.2f}M, {2:.2f}%)\\n\".format(FP, FP/mil, FP*hund/totReads)+ \\\n",
    "    \"Number of True Negatives(TN) reads: {0} ({1:.2f}M, {2:.2f}%)\\n\".format(TN, TN/mil, TN*hund/totReads)+ \\\n",
    "\t\"\\n ===================== \\n SECONDARY ACCURACY METRIC \\n =====================\\n\"+ \\\n",
    "    \"Senstivity: {}\\n\".format(sen)+ \\\n",
    "    \"Specificity: {}\\n\".format(spec)+ \\\n",
    "    \"Precision: {}\\n\".format(ppv)+ \\\n",
    "    \"Neg Pred. Value: {}\\n\".format(npv)+ \\\n",
    "    \"MCC: {}\\n\".format(mcc)+ \\\n",
    "    \"====================================================================================\\n\\n\\n\\n\"\n",
    "\n",
    "    filename = cwd + \"/report.txt\"\n",
    "    with open(filename, 'w') as f:\n",
    "        f.write(stText)\n",
    "    return sen, spec, ppv, npv, mcc\n",
    "\n",
    "def perform_counting(fname, totReads, TN, reads_list, id2phlm):\n",
    "    with pysam.AlignmentFile(fname) as f:\n",
    "        TP = 0\n",
    "        FP = 0\n",
    "        totCount = 0.0\n",
    "        singCount = 0\n",
    "        orphanCount = 0\n",
    "        for aln in f:\n",
    "            #get mate of the read\n",
    "            mate_aln = f.next()\n",
    "\n",
    "            # count total Number of reads\n",
    "            totCount += 1\n",
    "\n",
    "            # get number of alignments\n",
    "            n_alns = aln.get_tag('NH')\n",
    "\n",
    "            # for singly mapped reads only\n",
    "            if n_alns == 1:\n",
    "                # Increment the single count\n",
    "                singCount += 1\n",
    "\n",
    "            # Ignoring Orphan alignments for now\n",
    "            if(aln.reference_name != mate_aln.reference_name):\n",
    "                orphanCount += 1\n",
    "                print (\"WARNING: ORPHANS Detected statistics Neess to be re-evaluated\")\n",
    "                continue\n",
    "\n",
    "            # Progress Monitoring\n",
    "            if(round(totCount) % mil == 0):\n",
    "                print (\"\\r Done reading {} Million reads from BAM....\".format(int(round(totCount)/1000000)), end=\"\")\n",
    "                sys.stdout.flush()\n",
    "\n",
    "            qId = get_query_id(aln)\n",
    "\n",
    "            # list of all alignments\n",
    "            rIds = [get_ref_id(aln)]\n",
    "\n",
    "            # iterate over all alignments\n",
    "            for _ in range(1, n_alns):\n",
    "                aln = f.next()\n",
    "                mate_aln = f.next()\n",
    "\n",
    "                # Ignoring Orphan alignments for now\n",
    "                if(aln.reference_name != mate_aln.reference_name):\n",
    "                    orphanCount += 1\n",
    "                else:\n",
    "                    rIds.append(get_ref_id(aln))\n",
    "\n",
    "            # skip the whole alignment list of it's a Random read\n",
    "            if \"Random\" in aln.query_name:\n",
    "                TN -= 1\n",
    "                FP += 1\n",
    "                continue\n",
    "\n",
    "            plist = set([])\n",
    "            try:\n",
    "                qId_plm = id2phlm[qId]\n",
    "                for rId in rIds:\n",
    "                    rId_plm = id2phlm[rId]\n",
    "                    plist.add( rId_plm )\n",
    "                    if len(plist) > 1:\n",
    "                        break\n",
    "            except:\n",
    "                print (qId, rIds)\n",
    "                print_details(qId_plm, plist, aln)\n",
    "                break\n",
    "\n",
    "            if(len(plist) == 1 and list(plist)[0] == qId_plm):\n",
    "                TP += 1\n",
    "            else:\n",
    "#                 print_details(qId_plm, plist, aln)\n",
    "                FP += 1\n",
    "    return singCount, totCount, TP, FP, TN, orphanCount\n",
    "\n",
    "\n",
    "def get_stats(fq, sam):\n",
    "    pname = \"/mnt/scratch2/avi/meta-map/reads/meta/s2.tsv\"\n",
    "\n",
    "    # populate orgaism id to phylum dictionary\n",
    "    id2phlm = populate_phylum_dict(pname)\n",
    "\n",
    "    # parse the fastq file for TN calculations\n",
    "    totReads, TN, reads_list = parse_fq(fq)\n",
    "\n",
    "    # Parse the BAM and perform the counting\n",
    "    singCount, totCount, TP, FP, TN, orphanCount = perform_counting(sam, totReads, TN, reads_list, id2phlm)\n",
    "\n",
    "    # Calculate the stats and print it\n",
    "    sen, spec, ppv, npv, mcc = print_stats(singCount, totCount, totReads, TP, FP, TN, orphanCount)\n",
    "    print (\"\\noutput written to {}\".format(os.getcwd()+\"/reports.txt\"))\n",
    "\n",
    "    return sen, spec, ppv, npv, mcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Done reading 20 Million reads from BAM....\n",
      "\n",
      "====================================================================================\n",
      "Total Number of reads: 28912773 (28.00M)\n",
      "Number of Unmapped reads: 8164378.0 (8.16M, 28.24%)\n",
      "Number of Mapped reads 20748395.0(20.75M, 71.76%)\n",
      "\n",
      "\n",
      "============================ OUT OF MAPPED READS ===================================\n",
      "Number of Singly Mapped reads: 17442310 (17.00M, 60.00%)\n",
      "Number of Multimapped reads: 3306085.0 (3.31M, 11.43%)\n",
      "Number of Orphaned (Ignored)ALIGNMENTS (Should be significantly low): 0\n",
      "====================================================================================\n",
      "\n",
      " ===================== \n",
      " ACCURACY METRIC \n",
      " =====================\n",
      "Number of True positives(TP) reads: 20713041 (20.00M, 71.00%)\n",
      "Number of False Negatives(FN) reads: 2381814 (2.00M, 8.00%)\n",
      "Number of False positives(FP) reads: 35354 (0.00M, 0.00%)\n",
      "Number of True Negatives(TN) reads: 5782564 (5.00M, 20.00%)\n",
      "\n",
      " ===================== \n",
      " ACCURACY METRIC \n",
      " =====================\n",
      "Senstivity: 0.896868198566\n",
      "Specificity: 0.993923255708\n",
      "Precision: 0.998296060972\n",
      "Neg Pred. Value: 0.708267549592\n",
      "MCC: 0.793347859511\n",
      "====================================================================================\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Done reading 20 Million reads from BAM....\n",
      "output written to /mnt/scratch2/avi/meta-map/src-py/reports.txt\n"
     ]
    }
   ],
   "source": [
    "sen, spec, ppv, npv, mcc = get_stats(\"../reads/A1_1.fastq\", \"../pipeline/output/A1.sam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "puffMap = (sen, spec, ppv, mcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# puffMap = (sen, spec, ppv, mcc)\n",
    "CLARK = (1.0000, 0.8081, 0.9528, 0.8775)\n",
    "OneCodex = (0.9197, 1.0000, 1.0000, 0.8342)\n",
    "Kraken = (0.8984, 1.0000, 1.0000, 0.7993)\n",
    "MG_RAST = (0.7903, 0.9930, 0.9978, 0.6515)\n",
    "MEGAN = (0.5622, 0.9904, 0.9957, 0.4459)\n",
    "GOTTCHA = (0.5388, 1.0000, 1.0000, 0.4352)\n",
    "genomata = (0.4651, 0.9869, 0.9929, 0.3756)\n",
    "LMAT = (0.6442, 0.7360, 0.9052, 0.3089)\n",
    "taxator_tk = (0.5577, 0.7657, 0.8707, 0.2845)\n",
    "MetaPhlan = (0.0604, 1.0000, 1.0000, 0.1126)\n",
    "MetaPhyler = (0.0057, 0.9999, 0.9949, 0.0331)\n",
    "mOTU = (0.0020, 1.0000, 1.0000, 0.0201)\n",
    "QIIME = (0.0005, 1.0000, 0.9981, 0.0100)\n",
    "EBI = (0.0006, 0.9984, 0.5884, -0.0146)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/avi/miniconda2/lib/python2.7/site-packages/IPython/html.py:14: ShimWarning: The `IPython.html` package has been deprecated since IPython 4.0. You should import from `notebook` instead. `IPython.html.widgets` has moved to `ipywidgets`.\n",
      "  \"`IPython.html.widgets` has moved to `ipywidgets`.\", ShimWarning)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from ggplot import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame([puffMap, taxator_tk, QIIME, OneCodex, mOTU, MG_RAST, MetaPhlan, MetaPhyler, MEGAN, LMAT, Kraken, GOTTCHA, genomata, EBI, CLARK])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.columns = ['Senstivity', 'Specificity', 'Precision', 'Matthews correlation coefficient ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.index = [\"PuffMap\", \"taxator_tk\", \"QIIME\", \"OneCodex\", \"mOTU\", \"MG_RAST\", \"MetaPhlan\", \"MetaPhyler\", \"MEGAN\", \"LMAT\", \"Kraken\", \"GOTTCHA\", \"genomata\", \"EBI\", \"CLARK\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df.to_csv('stats.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Senstivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Matthews correlation coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PuffMap</th>\n",
       "      <td>0.896868</td>\n",
       "      <td>0.993923</td>\n",
       "      <td>0.998296</td>\n",
       "      <td>0.793348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>taxator_tk</th>\n",
       "      <td>0.557700</td>\n",
       "      <td>0.765700</td>\n",
       "      <td>0.870700</td>\n",
       "      <td>0.284500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QIIME</th>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998100</td>\n",
       "      <td>0.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OneCodex</th>\n",
       "      <td>0.919700</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.834200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mOTU</th>\n",
       "      <td>0.002000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.020100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MG_RAST</th>\n",
       "      <td>0.790300</td>\n",
       "      <td>0.993000</td>\n",
       "      <td>0.997800</td>\n",
       "      <td>0.651500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MetaPhlan</th>\n",
       "      <td>0.060400</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.112600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MetaPhyler</th>\n",
       "      <td>0.005700</td>\n",
       "      <td>0.999900</td>\n",
       "      <td>0.994900</td>\n",
       "      <td>0.033100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MEGAN</th>\n",
       "      <td>0.562200</td>\n",
       "      <td>0.990400</td>\n",
       "      <td>0.995700</td>\n",
       "      <td>0.445900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LMAT</th>\n",
       "      <td>0.644200</td>\n",
       "      <td>0.736000</td>\n",
       "      <td>0.905200</td>\n",
       "      <td>0.308900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kraken</th>\n",
       "      <td>0.898400</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.799300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GOTTCHA</th>\n",
       "      <td>0.538800</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.435200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>genomata</th>\n",
       "      <td>0.465100</td>\n",
       "      <td>0.986900</td>\n",
       "      <td>0.992900</td>\n",
       "      <td>0.375600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EBI</th>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.998400</td>\n",
       "      <td>0.588400</td>\n",
       "      <td>-0.014600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CLARK</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.808100</td>\n",
       "      <td>0.952800</td>\n",
       "      <td>0.877500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Senstivity  Specificity  Precision  \\\n",
       "PuffMap       0.896868     0.993923   0.998296   \n",
       "taxator_tk    0.557700     0.765700   0.870700   \n",
       "QIIME         0.000500     1.000000   0.998100   \n",
       "OneCodex      0.919700     1.000000   1.000000   \n",
       "mOTU          0.002000     1.000000   1.000000   \n",
       "MG_RAST       0.790300     0.993000   0.997800   \n",
       "MetaPhlan     0.060400     1.000000   1.000000   \n",
       "MetaPhyler    0.005700     0.999900   0.994900   \n",
       "MEGAN         0.562200     0.990400   0.995700   \n",
       "LMAT          0.644200     0.736000   0.905200   \n",
       "Kraken        0.898400     1.000000   1.000000   \n",
       "GOTTCHA       0.538800     1.000000   1.000000   \n",
       "genomata      0.465100     0.986900   0.992900   \n",
       "EBI           0.000600     0.998400   0.588400   \n",
       "CLARK         1.000000     0.808100   0.952800   \n",
       "\n",
       "            Matthews correlation coefficient   \n",
       "PuffMap                              0.793348  \n",
       "taxator_tk                           0.284500  \n",
       "QIIME                                0.010000  \n",
       "OneCodex                             0.834200  \n",
       "mOTU                                 0.020100  \n",
       "MG_RAST                              0.651500  \n",
       "MetaPhlan                            0.112600  \n",
       "MetaPhyler                           0.033100  \n",
       "MEGAN                                0.445900  \n",
       "LMAT                                 0.308900  \n",
       "Kraken                               0.799300  \n",
       "GOTTCHA                              0.435200  \n",
       "genomata                             0.375600  \n",
       "EBI                                 -0.014600  \n",
       "CLARK                                0.877500  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
