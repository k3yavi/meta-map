{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pysam\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "from __future__ import print_function\n",
    "import cPickle\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"../reads/meta/s2.tsv\") as f:\n",
    "    data = pd.read_table(f).set_index('EMBL ID').drop([\"Strain/species details\"], axis=1).to_dict()[\"Phylum\"]\n",
    "id2phlm = {}\n",
    "for k,v in data.items():\n",
    "    nk = k.split(\".\")[0]\n",
    "    id2phlm[nk] = v\n",
    "    if (nk == \"CM000636\"):\n",
    "        id2phlm[\"CP006835\"] = v\n",
    "del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Done reading 19 Million reads.\n",
      "\n",
      "====================================================================================\n",
      "Total Number of reads: 28912773 (28.00M)\n",
      "Number of Unmapped reads: 9577588.0 (9.58M, 33.13%)\n",
      "Number of Mapped reads 19335185.0(19.34M, 66.87%)\n",
      "\n",
      "\n",
      "============================ OUT OF MAPPED READS ===================================\n",
      "Number of Singly Mapped reads: 16087068 (16.00M, 55.00%)\n",
      "Number of Multimapped reads: 3248117.0 (3.25M, 11.23%)\n",
      "Number of Mapped but Skipped reads: 43.0 (0.00M, 0.00%)\n",
      "Number of Orphaned (Ignored)ALIGNMENTS (Should be significantly low): 0\n",
      "====================================================================================\n",
      "\n",
      " ===================== \n",
      " ASSUMPTIONS \n",
      " =====================\n",
      "1: Any Multi-mapped read has the Original Phyla in ATLEAST 1 alignment\n",
      "2: Don't know what to do with Rose Sequence Ignoring for now\n",
      "3: No reference of Eukaryotes added\n",
      "OVERALL: Atmost 10% Reads could have been mapped more.\n",
      "Eukaryotes Counts: 1445638(4.00%)\n",
      "Rose Counts: 1445638(4.00%)\n",
      "====================================================================================\n",
      "\n",
      " ===================== \n",
      " ACCURACY METRIC \n",
      " =====================\n",
      "Number of True positives(TP) reads: 19334560 (19.00M, 66.00%)\n",
      "Number of False Negatives(FN) reads: 903982 (0.00M, 3.00%)\n",
      "Number of False positives(FP) reads: 391 (0.00M, 0.00%)\n",
      "Number of True Negatives(TN) reads: 5782564 (5.00M, 20.00%)\n",
      "====================================================================================\n"
     ]
    }
   ],
   "source": [
    "mil = 1000000\n",
    "hund = 100\n",
    "\n",
    "def get_ref_id(aln):\n",
    "    # get id for the mapped reference\n",
    "    try:\n",
    "        return aln.reference_name.split(\"|\")[1]\n",
    "    except:\n",
    "        return aln.reference_name.split(\".\")[0]\n",
    "    \n",
    "def print_details(qId, rId, aln):\n",
    "    print (\"ERROR\")\n",
    "    print(\"SAM Algns\")\n",
    "    print (aln.query_name, aln.reference_name)\n",
    "    print(\"SUBSETTING\")\n",
    "    print (qId, rId)\n",
    "    print (\"PHYLA\")\n",
    "    print (id2phlm[qId], id2phlm[rId])\n",
    "\n",
    "\n",
    "def get_stats(fname, rname, level=\"phyla\"):\n",
    "    totReads = 0\n",
    "    TN = 0\n",
    "    FN = 0\n",
    "    reads_list = []\n",
    "    roseCount = 0\n",
    "    euCount = 0\n",
    "    with open(rname) as f:        \n",
    "        for line in f:\n",
    "            # counting total reads\n",
    "            totReads += 1\n",
    "            # Progress Monitoring\n",
    "            if(totReads % mil == 0):\n",
    "                print (\"\\r Done reading {} Million reads.\".format(int(round(totReads)/1000000)), end=\"\")\n",
    "            \n",
    "            #extracting relevant part of read\n",
    "            read = line.strip().replace(\"/1\",\"\").replace(\"@\",\"\")\n",
    "            \n",
    "            if \"Random\" in read:\n",
    "                TN += 1\n",
    "            if \"Eukaryotes\" in read:\n",
    "                euCount += 1\n",
    "            if \"Rose\" in read:\n",
    "                roseCount += 1\n",
    "            \n",
    "            #making a list of read id\n",
    "            reads_list.append(read)\n",
    "            \n",
    "            # skip next 4 lines\n",
    "            for _ in range(3):\n",
    "                f.next()\n",
    "    \n",
    "    if len(reads_list) != len(set(reads_list)):\n",
    "        print (\"ERROR: Repeating reads found\")\n",
    "        return 0\n",
    "\n",
    "# ++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "# Repeating Block\n",
    "# ++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "#     print(\"\\nSaving Pickle\")\n",
    "#     with open(r\"reads_list.pickle\", \"wb\") as f:\n",
    "#         cPickle.dump(reads_list, f)\n",
    "#     print(\"Done Saving Pickle\")\n",
    "# ++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "\n",
    "# ++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "# Repeating Block\n",
    "# ++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "#     print(\"Reading Pickle\")\n",
    "#     with open(r\"reads_list.pickle\", \"rb\") as f:\n",
    "#         reads_list = cPickle.load(f)\n",
    "#     totReads = len(reads_list)\n",
    "# ++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "    \n",
    "    with pysam.AlignmentFile(fname) as f:\n",
    "        TP = 0\n",
    "        FP = 0\n",
    "        totCount = 0.0\n",
    "        singCount = 0\n",
    "        orphanCount = 0\n",
    "        skipCount = 0.0\n",
    "        for aln in f:\n",
    "            #get mate of the read\n",
    "            mate_aln = f.next()\n",
    "            \n",
    "            # count total Number of reads\n",
    "            totCount += 1\n",
    "            \n",
    "            # get number of alignments\n",
    "            n_alns = aln.get_tag('NH')\n",
    "            \n",
    "            #ignoring Rose Sequence\n",
    "            if \"Rose\" in aln.query_name or \"Eukaryotes\" in aln.query_name:\n",
    "                skipCount += 1.0/n_alns\n",
    "                continue\n",
    "            \n",
    "            # Ignoring Orphan alignments for now\n",
    "            if(aln.reference_name != mate_aln.reference_name):\n",
    "                orphanCount += 1\n",
    "                print (\"WARNING: ORPHANS Detected statistics Neess to be re-evaluated\")\n",
    "                continue\n",
    "            \n",
    "            # Progress Monitoring\n",
    "            if(round(totCount) % mil == 0):\n",
    "                print (\"\\r Done reading {} Million reads.\".format(int(round(totCount)/1000000)), end=\"\")\n",
    "\n",
    "            # get ground truth id\n",
    "            qId = aln.query_name.split('-')[0]\n",
    "            if \"|\" in qId:\n",
    "                qId = qId.split(\"|\")[1]\n",
    "            elif \"_\" in qId:\n",
    "                qId = qId.split(\"_\")[0]\n",
    "                \n",
    "            # for singly mapped reads only\n",
    "            if n_alns == 1:\n",
    "                # Increment the single count\n",
    "                singCount += 1\n",
    "\n",
    "                # get id for the mapped reference\n",
    "                rId = get_ref_id(aln)\n",
    "                \n",
    "                # compare the labels\n",
    "                try:\n",
    "                    if qId == rId or id2phlm[qId]==id2phlm[rId]:\n",
    "                        # get TP count \n",
    "                        TP += 1\n",
    "                    else:\n",
    "#                         print_details(qId, rId, aln)\n",
    "                        # get FP count \n",
    "                        FP += 1\n",
    "                except:\n",
    "                    print (\"In Single mapping\")\n",
    "                    print_details(qId, rId, aln)\n",
    "\n",
    "                    \n",
    "            #handling MultiMapped Reads\n",
    "            else:\n",
    "                # list of all alignments\n",
    "                algns = [get_ref_id(aln)]\n",
    "                \n",
    "                # iterate over all alignments\n",
    "                for _ in range(1, n_alns):\n",
    "                    aln = f.next()\n",
    "                    mate_aln = f.next()\n",
    "                    \n",
    "                    # Ignoring Orphan alignments for now\n",
    "                    if(aln.reference_name != mate_aln.reference_name):\n",
    "                        orphanCount += 1\n",
    "                    else:\n",
    "                        algns.append(get_ref_id(aln))\n",
    "                \n",
    "                # SIMULATED FALSE POSITIVES\n",
    "                if \"Random\" in aln.query_name:\n",
    "                    TN -= 1\n",
    "                    FP += 1\n",
    "                    continue\n",
    "                \n",
    "                flag = False\n",
    "                for rId in algns:\n",
    "                    try:\n",
    "                        if qId == rId or id2phlm[qId]==id2phlm[rId]:\n",
    "                            flag = True\n",
    "                            break\n",
    "                    except:\n",
    "                        print (\"In Multimapping\")\n",
    "                        print_details(qId, rId, aln)\n",
    "\n",
    "                if flag:\n",
    "                    TP += 1\n",
    "                else:\n",
    "#                     print_details(qId, rId, aln)\n",
    "                    FP += 1\n",
    "    \n",
    "    mmCount = round(totCount - singCount)\n",
    "    unmapCount = totReads - totCount\n",
    "    FN = totReads - TP - FP - TN - roseCount - euCount\n",
    "    print (\"\\n\")\n",
    "    print (\"====================================================================================\")\n",
    "    print (\"Total Number of reads: {0} ({1:.2f}M)\".format(totReads, totReads/mil))    \n",
    "    print (\"Number of Unmapped reads: {0} ({1:.2f}M, {2:.2f}%)\".format(unmapCount, unmapCount/mil, unmapCount*hund/totReads))    \n",
    "    print (\"Number of Mapped reads {0}({1:.2f}M, {2:.2f}%)\".format(totCount, totCount/mil, totCount*hund/totReads))\n",
    "    print (\"\\n\")\n",
    "    print (\"============================ OUT OF MAPPED READS ===================================\")\n",
    "    print (\"Number of Singly Mapped reads: {0} ({1:.2f}M, {2:.2f}%)\".format(singCount, singCount/mil, singCount*hund/totReads))\n",
    "    print (\"Number of Multimapped reads: {0} ({1:.2f}M, {2:.2f}%)\".format(mmCount, mmCount/mil, mmCount*hund/totReads))\n",
    "    print (\"Number of Mapped but Skipped reads: {0} ({1:.2f}M, {2:.2f}%)\".format(skipCount, skipCount/mil, skipCount*hund/totReads))\n",
    "    print (\"Number of Orphaned (Ignored)ALIGNMENTS (Should be significantly low): {}\".format(orphanCount))\n",
    "    print (\"====================================================================================\")\n",
    "    print (\"\\n ===================== \\n ASSUMPTIONS \\n =====================\")\n",
    "    print (\"1: Any Multi-mapped read has the Original Phyla in ATLEAST 1 alignment\")\n",
    "    print (\"2: Don't know what to do with Rose Sequence Ignoring for now\")\n",
    "    print (\"3: No reference of Eukaryotes added\")\n",
    "    print (\"OVERALL: Atmost 10% Reads could have been mapped more.\")\n",
    "    print (\"Eukaryotes Counts: {0}({1:.2f}%)\".format(euCount, euCount*hund/totReads))\n",
    "    print (\"Rose Counts: {0}({1:.2f}%)\".format(roseCount, roseCount*hund/totReads))\n",
    "    print (\"====================================================================================\")\n",
    "    print (\"\\n ===================== \\n ACCURACY METRIC \\n =====================\")\n",
    "    print (\"Number of True positives(TP) reads: {0} ({1:.2f}M, {2:.2f}%)\".format(TP, TP/mil, TP*hund/totReads))\n",
    "    print (\"Number of False Negatives(FN) reads: {0} ({1:.2f}M, {2:.2f}%)\".format(FN, FN/mil, FN*hund/totReads))\n",
    "    print (\"Number of False positives(FP) reads: {0} ({1:.2f}M, {2:.2f}%)\".format(FP, FP/mil, FP*hund/totReads))\n",
    "    print (\"Number of True Negatives(TN) reads: {0} ({1:.2f}M, {2:.2f}%)\".format(TN, TN/mil, TN*hund/totReads))\n",
    "    print (\"====================================================================================\")\n",
    "    return TP,FP,FN,TN\n",
    "            \n",
    "TP,FP,FN,TN = get_stats(\"../bam/A1.sam\", \"../reads/A1_1.fastq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sen = TP/float(TP+FN)\n",
    "spec = TN/float(TN+FP)\n",
    "ppv = TP/float(TP+FP)\n",
    "npv = TN/float(TN+FN)\n",
    "mcc = ((TP*TN)-(FP*FN)) / math.sqrt( (TP+FP)*(TP+FN)*(TN+FP)*(TN+FN) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9553336401406781, 0.9999323875077707, 0.9999797775541298, 0.908900609159144)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " (sen, spec, ppv, mcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "puffMap = (sen, spec, ppv, mcc)\n",
    "taxator_tk = (0.5577, 0.7657, 0.8707, 0.2845)\n",
    "QIIME = (0.0005, 1.0000, 0.9981, 0.0100)\n",
    "OneCodex = (0.9197, 1.0000, 1.0000, 0.8342)\n",
    "mOTU = (0.0020, 1.0000, 1.0000, 0.0201)\n",
    "MG_RAST = (0.7903, 0.9930, 0.9978, 0.6515)\n",
    "MetaPhlan = (0.0604, 1.0000, 1.0000, 0.1126)\n",
    "MetaPhyler = (0.0057, 0.9999, 0.9949, 0.0331)\n",
    "MEGAN = (0.5622, 0.9904, 0.9957, 0.4459)\n",
    "LMAT = (0.6442, 0.7360, 0.9052, 0.3089)\n",
    "Kraken = (0.8984, 1.0000, 1.0000, 0.7993)\n",
    "GOTTCHA = (0.5388, 1.0000, 1.0000, 0.4352)\n",
    "genomata = (0.4651, 0.9869, 0.9929, 0.3756)\n",
    "EBI = (0.0006, 0.9984, 0.5884, -0.0146)\n",
    "CLARK = (1.0000, 0.8081, 0.9528, 0.8775)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/avi/miniconda2/lib/python2.7/site-packages/IPython/html.py:14: ShimWarning: The `IPython.html` package has been deprecated since IPython 4.0. You should import from `notebook` instead. `IPython.html.widgets` has moved to `ipywidgets`.\n",
      "  \"`IPython.html.widgets` has moved to `ipywidgets`.\", ShimWarning)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ggplot import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([puffMap, taxator_tk, QIIME, OneCodex, mOTU, MG_RAST, MetaPhlan, MetaPhyler, MEGAN, LMAT, Kraken, GOTTCHA, genomata, EBI, CLARK])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = ['Senstivity', 'Specificity', 'Precision', 'Matthews correlation coefficient ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index = [\"PuffMap\", \"taxator_tk\", \"QIIME\", \"OneCodex\", \"mOTU\", \"MG_RAST\", \"MetaPhlan\", \"MetaPhyler\", \"MEGAN\", \"LMAT\", \"Kraken\", \"GOTTCHA\", \"genomata\", \"EBI\", \"CLARK\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('stats.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
