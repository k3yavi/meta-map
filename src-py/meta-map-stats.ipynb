{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pysam\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "from __future__ import print_function\n",
    "import cPickle\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"../reads/meta/s2.tsv\") as f:\n",
    "    data = pd.read_table(f).set_index('EMBL ID').drop([\"Strain/species details\"], axis=1).to_dict()[\"Phylum\"]\n",
    "id2phlm = {}\n",
    "for k,v in data.items():\n",
    "    nk = k.split(\".\")[0]\n",
    "    id2phlm[nk] = v\n",
    "    if (nk == \"CM000636\"):\n",
    "        id2phlm[\"CP006835\"] = v\n",
    "    elif v == \"Rhizobium_Bradyrhizobium\":\n",
    "        id2phlm[nk] = \"Proteobacteria\"\n",
    "    elif v == \"Pathogens\":\n",
    "        id2phlm[nk] = \"Proteobacteria\"\n",
    "del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Done reading 19 Million reads.\n",
      "\n",
      "====================================================================================\n",
      "Total Number of reads: 28912773 (28.00M)\n",
      "Number of Unmapped reads: 9577588.0 (9.58M, 33.13%)\n",
      "Number of Mapped reads 19335185.0(19.34M, 66.87%)\n",
      "\n",
      "\n",
      "============================ OUT OF MAPPED READS ===================================\n",
      "Number of Singly Mapped reads: 16087082 (16.00M, 55.00%)\n",
      "Number of Multimapped reads: 3248103.0 (3.25M, 11.23%)\n",
      "Number of Mapped but Skipped reads: 43.0 (0.00M, 0.00%)\n",
      "Number of Orphaned (Ignored)ALIGNMENTS (Should be significantly low): 0\n",
      "====================================================================================\n",
      "\n",
      " ===================== \n",
      " ASSUMPTIONS \n",
      " =====================\n",
      "1: Any Multi-mapped read has the Original Phyla in ATLEAST 1 alignment\n",
      "2: Don't know what to do with Rose Sequence Ignoring for now\n",
      "3: No reference of Eukaryotes added\n",
      "OVERALL: Atmost 10% Reads could have been mapped more.\n",
      "Eukaryotes Counts: 1445638(4.00%)\n",
      "Rose Counts: 1445638(4.00%)\n",
      "====================================================================================\n",
      "\n",
      " ===================== \n",
      " ACCURACY METRIC \n",
      " =====================\n",
      "Number of True positives(TP) reads: 19299621 (19.00M, 66.00%)\n",
      "Number of False Negatives(FN) reads: 903982 (0.00M, 3.00%)\n",
      "Number of False positives(FP) reads: 35330 (0.00M, 0.00%)\n",
      "Number of True Negatives(TN) reads: 5782564 (5.00M, 20.00%)\n",
      "====================================================================================\n"
     ]
    }
   ],
   "source": [
    "mil = 1000000\n",
    "hund = 100\n",
    "\n",
    "def get_ref_id(aln):\n",
    "    # get id for the mapped reference\n",
    "    try:\n",
    "        return aln.reference_name.split(\"|\")[1]\n",
    "    except:\n",
    "        return aln.reference_name.split(\".\")[0]\n",
    "    \n",
    "def print_details(qId, rIds, aln):\n",
    "    print(\"PHYLA\")\n",
    "    print (\"QUERY:\\t\" + qId + \"\\tMAPPINGS:\\t\")\n",
    "    for rId in rIds:\n",
    "        print ( rId , end=\"\\t\")\n",
    "    print (\"\\n\")\n",
    "\n",
    "\n",
    "def get_stats(fname, rname):\n",
    "    totReads = 0\n",
    "    TN = 0\n",
    "    FN = 0\n",
    "    reads_list = []\n",
    "    roseCount = 0\n",
    "    euCount = 0\n",
    "    with open(rname) as f:        \n",
    "        for line in f:\n",
    "            # counting total reads\n",
    "            totReads += 1\n",
    "            # Progress Monitoring\n",
    "            if(totReads % mil == 0):\n",
    "                print (\"\\r Done reading {} Million reads.\".format(int(round(totReads)/1000000)), end=\"\")\n",
    "            \n",
    "            #extracting relevant part of read\n",
    "            read = line.strip().replace(\"/1\",\"\").replace(\"@\",\"\")\n",
    "            \n",
    "            if \"Random\" in read:\n",
    "                TN += 1\n",
    "            if \"Eukaryotes\" in read:\n",
    "                euCount += 1\n",
    "            if \"Rose\" in read:\n",
    "                roseCount += 1\n",
    "            \n",
    "            #making a list of read id\n",
    "            reads_list.append(read)\n",
    "            \n",
    "            # skip next 4 lines\n",
    "            for _ in range(3):\n",
    "                f.next()\n",
    "    \n",
    "    if len(reads_list) != len(set(reads_list)):\n",
    "        print (\"ERROR: Repeating reads found\")\n",
    "        return 0\n",
    "\n",
    "# ++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "# Repeating Block\n",
    "# ++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "#     print(\"\\nSaving Pickle\")\n",
    "#     with open(r\"reads_list.pickle\", \"wb\") as f:\n",
    "#         cPickle.dump(reads_list, f)\n",
    "#     print(\"Done Saving Pickle\")\n",
    "# ++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "\n",
    "# ++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "# Repeating Block\n",
    "# ++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "#     print(\"Reading Pickle\")\n",
    "#     with open(r\"reads_list.pickle\", \"rb\") as f:\n",
    "#         reads_list = cPickle.load(f)\n",
    "#     totReads = len(reads_list)\n",
    "# ++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "    \n",
    "    with pysam.AlignmentFile(fname) as f:\n",
    "        TP = 0\n",
    "        FP = 0\n",
    "        totCount = 0.0\n",
    "        singCount = 0\n",
    "        orphanCount = 0\n",
    "        skipCount = 0.0\n",
    "        for aln in f:\n",
    "            #get mate of the read\n",
    "            mate_aln = f.next()\n",
    "            \n",
    "            # count total Number of reads\n",
    "            totCount += 1\n",
    "            \n",
    "            # get number of alignments\n",
    "            n_alns = aln.get_tag('NH')\n",
    "            \n",
    "            # for singly mapped reads only\n",
    "            if n_alns == 1:\n",
    "                # Increment the single count\n",
    "                singCount += 1\n",
    "            \n",
    "            #ignoring Rose Sequence\n",
    "            if \"Rose\" in aln.query_name or \"Eukaryotes\" in aln.query_name:\n",
    "                skipCount += 1.0/n_alns\n",
    "                continue\n",
    "            \n",
    "            # Ignoring Orphan alignments for now\n",
    "            if(aln.reference_name != mate_aln.reference_name):\n",
    "                orphanCount += 1\n",
    "                print (\"WARNING: ORPHANS Detected statistics Neess to be re-evaluated\")\n",
    "                continue\n",
    "            \n",
    "            # Progress Monitoring\n",
    "            if(round(totCount) % mil == 0):\n",
    "                print (\"\\r Done reading {} Million reads.\".format(int(round(totCount)/1000000)), end=\"\")\n",
    "\n",
    "            # get ground truth id\n",
    "            qId = aln.query_name.split('-')[0]\n",
    "            if \"|\" in qId:\n",
    "                qId = qId.split(\"|\")[1]\n",
    "            elif \"_\" in qId:\n",
    "                qId = qId.split(\"_\")[0]\n",
    "                \n",
    "            # list of all alignments\n",
    "            rIds = [get_ref_id(aln)]\n",
    "\n",
    "            # iterate over all alignments\n",
    "            for _ in range(1, n_alns):\n",
    "                aln = f.next()\n",
    "                mate_aln = f.next()\n",
    "\n",
    "                # Ignoring Orphan alignments for now\n",
    "                if(aln.reference_name != mate_aln.reference_name):\n",
    "                    orphanCount += 1\n",
    "                else:\n",
    "                    rIds.append(get_ref_id(aln))\n",
    "            \n",
    "            # skip the whole alignment list of it's a Random read\n",
    "            if \"Random\" in aln.query_name:\n",
    "                TN -= 1\n",
    "                FP += 1\n",
    "                continue\n",
    "                \n",
    "            flag = False\n",
    "            plist = set([])\n",
    "            try:\n",
    "                qId_plm = id2phlm[qId]\n",
    "                for rId in rIds:\n",
    "                    rId_plm = id2phlm[rId]\n",
    "                    plist.add( rId_plm )\n",
    "                    if len(plist) > 1:\n",
    "                        break\n",
    "            except:\n",
    "                print_details(qId_plm, rIds, aln)\n",
    "\n",
    "            if(len(plist) == 1 and list(plist)[0] == qId_plm):\n",
    "                TP += 1\n",
    "            else:\n",
    "#                 print_details(qId, rId, aln)\n",
    "                FP += 1\n",
    "    \n",
    "    mmCount = round(totCount - singCount)\n",
    "    unmapCount = totReads - totCount\n",
    "    FN = totReads - TP - FP - TN - roseCount - euCount\n",
    "    sen = TP/float(TP+FN)\n",
    "    spec = TN/float(TN+FP)\n",
    "    ppv = TP/float(TP+FP)\n",
    "    npv = TN/float(TN+FN)\n",
    "    mcc = ((TP*TN)-(FP*FN)) / math.sqrt( (TP+FP)*(TP+FN)*(TN+FP)*(TN+FN) )\n",
    "    print (\"\\n\")\n",
    "    print (\"====================================================================================\")\n",
    "    print (\"Total Number of reads: {0} ({1:.2f}M)\".format(totReads, totReads/mil))    \n",
    "    print (\"Number of Unmapped reads: {0} ({1:.2f}M, {2:.2f}%)\".format(unmapCount, unmapCount/mil, unmapCount*hund/totReads))    \n",
    "    print (\"Number of Mapped reads {0}({1:.2f}M, {2:.2f}%)\".format(totCount, totCount/mil, totCount*hund/totReads))\n",
    "    print (\"\\n\")\n",
    "    print (\"============================ OUT OF MAPPED READS ===================================\")\n",
    "    print (\"Number of Singly Mapped reads: {0} ({1:.2f}M, {2:.2f}%)\".format(singCount, singCount/mil, singCount*hund/totReads))\n",
    "    print (\"Number of Multimapped reads: {0} ({1:.2f}M, {2:.2f}%)\".format(mmCount, mmCount/mil, mmCount*hund/totReads))\n",
    "    print (\"Number of Mapped but Skipped reads: {0} ({1:.2f}M, {2:.2f}%)\".format(skipCount, skipCount/mil, skipCount*hund/totReads))\n",
    "    print (\"Number of Orphaned (Ignored)ALIGNMENTS (Should be significantly low): {}\".format(orphanCount))\n",
    "    print (\"====================================================================================\")\n",
    "    print (\"\\n ===================== \\n ASSUMPTIONS \\n =====================\")\n",
    "    print (\"1: Any Multi-mapped read has the Original Phyla in ATLEAST 1 alignment\")\n",
    "    print (\"2: Don't know what to do with Rose Sequence Ignoring for now\")\n",
    "    print (\"3: No reference of Eukaryotes added\")\n",
    "    print (\"OVERALL: Atmost 10% Reads could have been mapped more.\")\n",
    "    print (\"Eukaryotes Counts: {0}({1:.2f}%)\".format(euCount, euCount*hund/totReads))\n",
    "    print (\"Rose Counts: {0}({1:.2f}%)\".format(roseCount, roseCount*hund/totReads))\n",
    "    print (\"====================================================================================\")\n",
    "    print (\"\\n ===================== \\n ACCURACY METRIC \\n =====================\")\n",
    "    print (\"Number of True positives(TP) reads: {0} ({1:.2f}M, {2:.2f}%)\".format(TP, TP/mil, TP*hund/totReads))\n",
    "    print (\"Number of False Negatives(FN) reads: {0} ({1:.2f}M, {2:.2f}%)\".format(FN, FN/mil, FN*hund/totReads))\n",
    "    print (\"Number of False positives(FP) reads: {0} ({1:.2f}M, {2:.2f}%)\".format(FP, FP/mil, FP*hund/totReads))\n",
    "    print (\"Number of True Negatives(TN) reads: {0} ({1:.2f}M, {2:.2f}%)\".format(TN, TN/mil, TN*hund/totReads))\n",
    "    print (\"\\n ===================== \\n ACCURACY METRIC \\n =====================\")\n",
    "    print (\"Senstivity: {}\".format(sen))\n",
    "    print (\"Specificity: {}\".format(spec))\n",
    "    print (\"Precision: {}\".format(ppv))\n",
    "    print (\"Neg Pred. Value: {}\".format(npv))\n",
    "    print (\"MCC: {}\".format(mcc))\n",
    "    print (\"====================================================================================\")\n",
    "    return TP,FP,FN,TN\n",
    "            \n",
    "TP,FP,FN,TN = get_stats(\"../bam/A1.sam\", \"../reads/A1_1.fastq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9552563965942115,\n",
       " 0.9939273558438844,\n",
       " 0.9981727390982268,\n",
       " 0.9050553804552882)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sen = TP/float(TP+FN)\n",
    "spec = TN/float(TN+FP)\n",
    "ppv = TP/float(TP+FP)\n",
    "npv = TN/float(TN+FN)\n",
    "mcc = ((TP*TN)-(FP*FN)) / math.sqrt( (TP+FP)*(TP+FN)*(TN+FP)*(TN+FN) )\n",
    "(sen, spec, ppv, mcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "puffMap = (sen, spec, ppv, mcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# puffMap = (sen, spec, ppv, mcc)\n",
    "taxator_tk = (0.5577, 0.7657, 0.8707, 0.2845)\n",
    "QIIME = (0.0005, 1.0000, 0.9981, 0.0100)\n",
    "OneCodex = (0.9197, 1.0000, 1.0000, 0.8342)\n",
    "mOTU = (0.0020, 1.0000, 1.0000, 0.0201)\n",
    "MG_RAST = (0.7903, 0.9930, 0.9978, 0.6515)\n",
    "MetaPhlan = (0.0604, 1.0000, 1.0000, 0.1126)\n",
    "MetaPhyler = (0.0057, 0.9999, 0.9949, 0.0331)\n",
    "MEGAN = (0.5622, 0.9904, 0.9957, 0.4459)\n",
    "LMAT = (0.6442, 0.7360, 0.9052, 0.3089)\n",
    "Kraken = (0.8984, 1.0000, 1.0000, 0.7993)\n",
    "GOTTCHA = (0.5388, 1.0000, 1.0000, 0.4352)\n",
    "genomata = (0.4651, 0.9869, 0.9929, 0.3756)\n",
    "EBI = (0.0006, 0.9984, 0.5884, -0.0146)\n",
    "CLARK = (1.0000, 0.8081, 0.9528, 0.8775)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/avi/miniconda2/lib/python2.7/site-packages/IPython/html.py:14: ShimWarning: The `IPython.html` package has been deprecated since IPython 4.0. You should import from `notebook` instead. `IPython.html.widgets` has moved to `ipywidgets`.\n",
      "  \"`IPython.html.widgets` has moved to `ipywidgets`.\", ShimWarning)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from ggplot import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame([puffMap, taxator_tk, QIIME, OneCodex, mOTU, MG_RAST, MetaPhlan, MetaPhyler, MEGAN, LMAT, Kraken, GOTTCHA, genomata, EBI, CLARK])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.columns = ['Senstivity', 'Specificity', 'Precision', 'Matthews correlation coefficient ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.index = [\"PuffMap\", \"taxator_tk\", \"QIIME\", \"OneCodex\", \"mOTU\", \"MG_RAST\", \"MetaPhlan\", \"MetaPhyler\", \"MEGAN\", \"LMAT\", \"Kraken\", \"GOTTCHA\", \"genomata\", \"EBI\", \"CLARK\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df.to_csv('stats.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Senstivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Matthews correlation coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PuffMap</th>\n",
       "      <td>0.955256</td>\n",
       "      <td>0.993927</td>\n",
       "      <td>0.998173</td>\n",
       "      <td>0.905055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>taxator_tk</th>\n",
       "      <td>0.557700</td>\n",
       "      <td>0.765700</td>\n",
       "      <td>0.870700</td>\n",
       "      <td>0.284500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QIIME</th>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998100</td>\n",
       "      <td>0.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OneCodex</th>\n",
       "      <td>0.919700</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.834200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mOTU</th>\n",
       "      <td>0.002000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.020100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MG_RAST</th>\n",
       "      <td>0.790300</td>\n",
       "      <td>0.993000</td>\n",
       "      <td>0.997800</td>\n",
       "      <td>0.651500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MetaPhlan</th>\n",
       "      <td>0.060400</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.112600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MetaPhyler</th>\n",
       "      <td>0.005700</td>\n",
       "      <td>0.999900</td>\n",
       "      <td>0.994900</td>\n",
       "      <td>0.033100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MEGAN</th>\n",
       "      <td>0.562200</td>\n",
       "      <td>0.990400</td>\n",
       "      <td>0.995700</td>\n",
       "      <td>0.445900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LMAT</th>\n",
       "      <td>0.644200</td>\n",
       "      <td>0.736000</td>\n",
       "      <td>0.905200</td>\n",
       "      <td>0.308900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kraken</th>\n",
       "      <td>0.898400</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.799300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GOTTCHA</th>\n",
       "      <td>0.538800</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.435200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>genomata</th>\n",
       "      <td>0.465100</td>\n",
       "      <td>0.986900</td>\n",
       "      <td>0.992900</td>\n",
       "      <td>0.375600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EBI</th>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.998400</td>\n",
       "      <td>0.588400</td>\n",
       "      <td>-0.014600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CLARK</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.808100</td>\n",
       "      <td>0.952800</td>\n",
       "      <td>0.877500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Senstivity  Specificity  Precision  \\\n",
       "PuffMap       0.955256     0.993927   0.998173   \n",
       "taxator_tk    0.557700     0.765700   0.870700   \n",
       "QIIME         0.000500     1.000000   0.998100   \n",
       "OneCodex      0.919700     1.000000   1.000000   \n",
       "mOTU          0.002000     1.000000   1.000000   \n",
       "MG_RAST       0.790300     0.993000   0.997800   \n",
       "MetaPhlan     0.060400     1.000000   1.000000   \n",
       "MetaPhyler    0.005700     0.999900   0.994900   \n",
       "MEGAN         0.562200     0.990400   0.995700   \n",
       "LMAT          0.644200     0.736000   0.905200   \n",
       "Kraken        0.898400     1.000000   1.000000   \n",
       "GOTTCHA       0.538800     1.000000   1.000000   \n",
       "genomata      0.465100     0.986900   0.992900   \n",
       "EBI           0.000600     0.998400   0.588400   \n",
       "CLARK         1.000000     0.808100   0.952800   \n",
       "\n",
       "            Matthews correlation coefficient   \n",
       "PuffMap                              0.905055  \n",
       "taxator_tk                           0.284500  \n",
       "QIIME                                0.010000  \n",
       "OneCodex                             0.834200  \n",
       "mOTU                                 0.020100  \n",
       "MG_RAST                              0.651500  \n",
       "MetaPhlan                            0.112600  \n",
       "MetaPhyler                           0.033100  \n",
       "MEGAN                                0.445900  \n",
       "LMAT                                 0.308900  \n",
       "Kraken                               0.799300  \n",
       "GOTTCHA                              0.435200  \n",
       "genomata                             0.375600  \n",
       "EBI                                 -0.014600  \n",
       "CLARK                                0.877500  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
