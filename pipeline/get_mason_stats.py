from __future__ import print_function
import pysam
import os
import click
import sys
from collections import defaultdict

mil = 1000000
hund = 100

def print_stats(singCount, totCount, orphanCount, phlmDict):
    mmCount = round(totCount - singCount)
    cwd = os.getcwd()

    stText = "\n\n" + \
    "====================================================================================\n" + \
        "Number of Mapped reads {0}({1:.2f}M)\n".format(totCount, totCount/mil)+ \
    "\n\n"+ \
    "============================ OUT OF MAPPED READS ===================================\n"+ \
    "Number of Singly Mapped reads: {0} ({1:.2f}M, {2:.2f}%)\n".format(singCount, singCount/mil, singCount*hund/totCount)+ \
    "Number of Multimapped reads: {0} ({1:.2f}M, {2:.2f}%)\n".format(mmCount, mmCount/mil, mmCount*hund/totCount)+ \
    "Number of Orphaned (Ignored)ALIGNMENTS (Should be significantly low): {}\n".format(orphanCount)+ \
    "====================================================================================\n\n\n\n"

    filename = cwd + "/report.txt"
    with open(filename, 'w') as f:
        f.write(stText)

    with open(cwd+"dist.txt", 'w') as f:
        for k,v in phlmDict.keys():
            f.write(k+","+str(v)+"\n")

def perform_counting(fname, id2phlm):
    with pysam.AlignmentFile(fname) as f:
        totCount = 0.0
        singCount = 0
        orphanCount = 0
        phlmDict = defaultdict(int)
        for aln in f:
            #get mate of the read
            mate_aln = f.next()

            # count total Number of reads
            totCount += 1

            # get number of alignments
            n_alns = aln.get_tag('NH')

            # for singly mapped reads only
            if n_alns == 1:
                # Increment the single count
                singCount += 1

            # Ignoring Orphan alignments for now
            if(aln.reference_name != mate_aln.reference_name):
                orphanCount += 1
                print ("WARNING: ORPHANS Detected statistics Neess to be re-evaluated")
                continue

            # Progress Monitoring
            if(round(totCount) % mil == 0):
                print ("\r Done reading {} Million reads from BAM....".format(int(round(totCount)/1000000)), end="")
                sys.stdout.flush()

            # query doesn't matter since not known
            # qId = aln.query_name

            # list of all alignments
            rIds = set([id2phlm[ aln.reference_name ]])

            # iterate over all alignments
            for _ in range(1, n_alns):
                aln = f.next()
                mate_aln = f.next()

                # Ignoring Orphan alignments for now
                if(aln.reference_name != mate_aln.reference_name):
                    orphanCount += 1
                else:
                    rIds.add(id2phlm[ aln.reference_name ])

            if len(rIds) == 1:
                phlmDict[list(rIds)[0]] += 1

    return singCount, totCount, orphanCount, phlmDict

def get_phlm_dict():
    id2phlm={}
    with open("/mnt/scratch2/avi/meta-map/kraken/meta/taxa.csv") as f:
            for line in f:
                toks = line.strip().split(",")
                val = toks[0]
                for i in range(1, len(toks)):
                    id2phlm[toks[i]] = val
    return id2phlm

@click.command()
@click.option('--sam',  help='path for the sam file generated by pufmap')
def get_stats(sam):
    #get taxa dict
    id2phlm = get_phlm_dict()

    ## Parse the BAM and perform the counting
    singCount, totCount, orphanCount, phlmDict = perform_counting(sam, id2phlm)

    ## Calculate the stats and print it
    print_stats(singCount, totCount, orphanCount, phlmDict)
    print ("\noutput written to {}".format(os.getcwd()+"/report.txt"))

if __name__=="__main__":
    get_stats()
